"""
DQN ëª¨ë¸ í‰ê°€ ì½”ë“œ - ì‹œê°ì  ë Œë”ë§ í¬í•¨
"""

import pygame
import math
import numpy as np
import torch
import torch.nn as nn
import copy
import os
import sys

current_dir = os.path.dirname(os.path.abspath(__file__))
root_dir = os.path.join(current_dir, "..")
sys.path.append(root_dir)

# ì´ì œ ìƒëŒ€ ê²½ë¡œ(..) ì—†ì´ ë°”ë¡œ envì—ì„œ ì„í¬íŠ¸ ê°€ëŠ¥í•©ë‹ˆë‹¤.
from env.racing_game_2d import RacingGame


# í‰ê°€ìš© DQN Class
class DQN:
    def __init__(self, input_size=28, output_size=6, layer_num=3, max_size=512):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.output_size = output_size
        self.layer_num = layer_num
        self.max_size = max_size
        
        self.model = self.create_model(input_size, output_size, layer_num, max_size).to(self.device)
        
        # 6ê°œ ì•¡ì…˜ + ê³ ì •ëœ frame ìˆ˜ ë§¤í•‘
        self.action_repeat_map = {
            0: 5,   # ì§ì§„
            1: 5,   # ì§ì§„+ì¢Œ
            2: 5,   # ì§ì§„+ìš°
            3: 5,  # ì§ì§„+ë¸Œë ˆì´í¬+ì¢Œ (ë“œë¦¬í”„íŠ¸)
            4: 5,  # ì§ì§„+ë¸Œë ˆì´í¬+ìš° (ë“œë¦¬í”„íŠ¸)
            5: 2,   # ë¸Œë ˆì´í¬
        }
    
    # ëª¨ë¸ ìƒì„± (DQN ì´ë¯€ë¡œ ë‹¨ìˆœí•œ layer ë‚˜ì—´)    
    def create_model(self, input_size, output_size, layer_num, max_size):
        layers = []
        
        layers.append(nn.Linear(input_size, max_size))
        layers.append(nn.ReLU())
        
        current_size = max_size
        for i in range(layer_num - 1):
            next_size = current_size // 2
            layers.append(nn.Linear(current_size, next_size))
            layers.append(nn.ReLU())
            current_size = next_size
        
        layers.append(nn.Linear(current_size, output_size))
        
        return nn.Sequential(*layers)
    
    # ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
    def load_model(self, path):
        self.model.load_state_dict(torch.load(path, map_location=self.device))
        self.model.eval()
        print(f"Model loaded from: {path}")
    
    def get_real_action(self, action_index): 
        """6ê°œì˜ ë‹¨ìˆœí™”ëœ ì•¡ì…˜ì„ ì‹¤ì œ ì»¨íŠ¸ë¡¤ë¡œ ë³€í™˜"""
        actions = {
            # ì§ì§„
            0: {'forward': True, 'backward': False, 'left': False, 'right': False, 'brake': False},
            # ì§ì§„ + ì¢Œ
            1: {'forward': True, 'backward': False, 'left': True, 'right': False, 'brake': False},
            # ì§ì§„ + ìš°
            2: {'forward': True, 'backward': False, 'left': False, 'right': True, 'brake': False},
            # ì§ì§„ + ë¸Œë ˆì´í¬ + ì¢Œ (ë“œë¦¬í”„íŠ¸ ì•¡ì…˜)
            3: {'forward': True, 'backward': False, 'left': True, 'right': False, 'brake': True},
            # ì§ì§„ + ë¸Œë ˆì´í¬ + ìš° (ë“œë¦¬í”„íŠ¸ ì•¡ì…˜)
            4: {'forward': True, 'backward': False, 'left': False, 'right': True, 'brake': True},
            # ë¸Œë ˆì´í¬
            5: {'forward': False, 'backward': False, 'left': False, 'right': False, 'brake': True},
        }
        return actions.get(action_index, actions[0])
    
    def get_action_frames(self, action_index):
        """ì•¡ì…˜ì— í•´ë‹¹í•˜ëŠ” í”„ë ˆì„ ìˆ˜ ë°˜í™˜"""
        return self.action_repeat_map.get(action_index, 3)
    
    def predict(self, state):
        with torch.no_grad():
            state_tensor = torch.FloatTensor(state).unsqueeze(0).to(self.device)
            q_values = self.model(state_tensor)
            return q_values, q_values.argmax().item()

# ì„¼ì„œ ë°ì´í„° ì¶”ì¶œ
def get_sensors(game):
    sensors = []
    sensor_range = game.car.sensor_range
    direction_num = 12
    # 12 ë°©í–¥ì— í•´ë‹¹í•˜ëŠ” ê±°ë¦¬ ê³„ì‚°. (sensor_range ë§Œí¼)
    for i in range(direction_num):
        angle = game.car.angle + (i * math.pi / (direction_num/2))
        # ë²½ê¹Œì§€ì˜ ê±°ë¦¬ë˜í•œ ê³„ì‚°í•˜ê¸° ìœ„í•´ 5ì”© ê³„ì‚° ì§„í–‰.
        for d in range(0, sensor_range, 5):
            x = int(game.car.x + math.cos(angle) * d)
            y = int(game.car.y + math.sin(angle) * d)
            if (x < 0 or y < 0 or 
                x >= game.track_mask.shape[1] or 
                y >= game.track_mask.shape[0] or
                game.track_mask[y, x] == 0):
                sensors.append(d)
                break
        else:
            sensors.append(sensor_range)
    return sensors

# State ë°ì´í„° ì¶”ì¶œ
def get_data(game, standard_cp=None, dis_gap=None): 
    angle = game.car.angle
    cos_angle = (math.cos(angle) + 1) / 2
    sin_angle = (math.sin(angle) + 1) / 2
    speed = game.car.speed / game.car.max_speed
    vel_x = game.car.velocity_x / game.car.max_speed
    vel_y = game.car.velocity_y / game.car.max_speed
    sensors = [sensor / game.car.sensor_range for sensor in get_sensors(game)]
    
    if standard_cp is not None and dis_gap is not None and dis_gap > 0:
        # ì²´í¬í¬ì¸íŠ¸ê¹Œì§€ ê±°ë¦¬
        current_distance = math.dist([game.car.x, game.car.y], standard_cp)
        normalized_dist = min(current_distance / dis_gap, 1.5)
        is_drifting = 1.0 if game.car.is_drifting else 0.0
        # ì²´í¬í¬ì¸íŠ¸ ë°©í–¥ (ìƒëŒ€ ê°ë„)
        dx = standard_cp[0] - game.car.x
        dy = standard_cp[1] - game.car.y
        target_angle = math.atan2(dy, dx)
        relative_angle = target_angle - game.car.angle
        
        # -Ï€ ~ Ï€ ì •ê·œí™”
        while relative_angle > math.pi:
            relative_angle -= 2 * math.pi
        while relative_angle < -math.pi:
            relative_angle += 2 * math.pi
        
        # 0~1ë¡œ ì •ê·œí™”
        normalized_angle = (relative_angle + math.pi) / (2 * math.pi)
    else:
        normalized_dist = 1.0
        normalized_angle = 0.5
        is_drifting = 0.0
    
    car_features = [
        game.car.max_speed / 1000,              # ìµœëŒ€ì†ë„ (0~1 ì •ê·œí™”)
        game.car.acceleration_force / 1000,     # ê°€ì†ë ¥
        game.car.brake_force / 1000, 
        game.car.base_friction,                # ë§ˆì°°ê³„ìˆ˜ (ì´ë¯¸ 0~1)
        game.car.lateral_friction,       # ì¸¡ë©´ ë§ˆì°° (ì´ë¯¸ 0~1)
        game.car.turn_speed / 10,               # íšŒì „ì†ë„
        game.car.drift_lateral_friction,                # ë“œë¦¬í”„íŠ¸ ë§ˆì°° (ì´ë¯¸ 0~1)
        game.car.sensor_range / 1000            # ì„¼ì„œ ë²”ìœ„ (0~1 ì •ê·œí™”)
    ]
    
    return sensors + [cos_angle, sin_angle, speed, vel_x, vel_y, normalized_dist, normalized_angle, is_drifting] + car_features


def draw_sensors(screen, game, camera_offset):
    """ì„¼ì„œ ì‹œê°í™”"""
    sensor_range = game.car.sensor_range
    direction_num = 12
    for i in range(direction_num):
        angle = game.car.angle + (i * math.pi / (direction_num/2))
        for d in range(0, sensor_range, 5):
            x = int(game.car.x + math.cos(angle) * d)
            y = int(game.car.y + math.sin(angle) * d)
            if (x < 0 or y < 0 or 
                x >= game.track_mask.shape[1] or 
                y >= game.track_mask.shape[0] or
                game.track_mask[y, x] == 0):
                # ì„¼ì„œ ëì  ê·¸ë¦¬ê¸°
                end_x = game.car.x + math.cos(angle) * d - camera_offset[0]
                end_y = game.car.y + math.sin(angle) * d - camera_offset[1]
                start_x = game.car.x - camera_offset[0]
                start_y = game.car.y - camera_offset[1]
                pygame.draw.line(screen, (0, 255, 0), (start_x, start_y), (end_x, end_y), 1)
                pygame.draw.circle(screen, (255, 0, 0), (int(end_x), int(end_y)), 3)
                break
        else:
            # ìµœëŒ€ ê±°ë¦¬ê¹Œì§€ ë„ë‹¬
            end_x = game.car.x + math.cos(angle) * sensor_range - camera_offset[0]
            end_y = game.car.y + math.sin(angle) * sensor_range - camera_offset[1]
            start_x = game.car.x - camera_offset[0]
            start_y = game.car.y - camera_offset[1]
            pygame.draw.line(screen, (0, 255, 0), (start_x, start_y), (end_x, end_y), 1)


def draw_q_values(screen, q_values, current_action, font):
    """
    Q-values ì‹œê°í™”
    - ê° actionì— ëŒ€í•œ Qê°’ì„ ë°” ì°¨íŠ¸ë¡œ í‘œì‹œ
    - í˜„ì¬ ì„ íƒëœ actionì„ í•˜ì´ë¼ì´íŠ¸
    """
    action_names = ['Forward', 'Fwd+Left', 'Fwd+Right', 'Drift L', 'Drift R', 'Brake']
    
    q_vals = q_values.cpu().numpy().flatten()
    max_q = max(q_vals)
    min_q = min(q_vals)
    
    x_start = 10
    y_start = 150
    bar_width = 100
    bar_height = 20
    
    title = font.render("Q-Values:", True, (0, 0, 0))
    screen.blit(title, (x_start, y_start - 25))
    
    for i, (name, q_val) in enumerate(zip(action_names, q_vals)):
        y = y_start + i * (bar_height + 5)
        
        # ë°°ê²½ ë°”
        pygame.draw.rect(screen, (200, 200, 200), (x_start, y, bar_width, bar_height))
        
        # Q-value ë°”
        if max_q != min_q:
            normalized = (q_val - min_q) / (max_q - min_q)
        else:
            normalized = 0.5
        
        if i == current_action:
            color = (0, 200, 0)  # ì„ íƒëœ ì•¡ì…˜ì€ ë…¹ìƒ‰
        else:
            color = (100, 100, 255)
        
        pygame.draw.rect(screen, color, (x_start, y, int(bar_width * normalized), bar_height))
        pygame.draw.rect(screen, (0, 0, 0), (x_start, y, bar_width, bar_height), 1)
        
        # ì•¡ì…˜ ì´ë¦„ê³¼ Q-value
        text = font.render(f"{name}: {q_val:.1f}", True, (0, 0, 0))
        screen.blit(text, (x_start + bar_width + 10, y))

import re

def parse_model_name(model_name):
    """
    ëª¨ë¸ ì´ë¦„ì—ì„œ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
    
    Args:
        model_name (str): ëª¨ë¸ íŒŒì¼ ì´ë¦„
        
    Returns:
        dict: layer_num, max_size, save_episodeë¥¼ ë‹´ì€ ë”•ì…”ë„ˆë¦¬
    """
    pattern = r"_L(\d+)_S(\d+)_E(\d+)"
    match = re.search(pattern, model_name)
    
    if match:
        return {
            'layer_num': int(match.group(1)),
            'max_size': int(match.group(2)),
            'save_episode': int(match.group(3))
        }
    else:
        raise ValueError(f"íŒŒì‹± ì‹¤íŒ¨: {model_name}")

def evaluate_dqn(model_path, track_file, car_json_path, layer_num=3, max_size=512, 
                 num_episodes=5, show_sensors=True, show_q_values=True, speed_multiplier=1.0):
    """
    DQN ëª¨ë¸ í‰ê°€ í•¨ìˆ˜
    - í•™ìŠµëœ ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ ì‹œê°ì  ë Œë”ë§ê³¼ í•¨ê»˜ í‰ê°€
    - ì„¼ì„œ ë° Qê°’ ì‹œê°í™” ì˜µì…˜ ì œê³µ
    - ì„±ê³µë¥  ë° í‰ê·  ì‹œê°„ ê³„ì‚°
    
    Args:
        model_path: í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
        track_file: íŠ¸ë™ JSON íŒŒì¼ ê²½ë¡œ
        car_json_path: ì°¨ëŸ‰ ì„¤ì • JSON íŒŒì¼ ê²½ë¡œ
        layer_num: ëª¨ë¸ ë ˆì´ì–´ ìˆ˜
        max_size: ëª¨ë¸ ìµœëŒ€ hidden size
        num_episodes: í‰ê°€í•  ì—í”¼ì†Œë“œ ìˆ˜
        show_sensors: ì„¼ì„œ ì‹œê°í™” ì—¬ë¶€
        show_q_values: Q-values ì‹œê°í™” ì—¬ë¶€
        speed_multiplier: ê²Œì„ ì†ë„ ë°°ìœ¨ (1.0 = ì •ìƒ, 2.0 = 2ë°°ì†)
    """
    pygame.init()
    
    model_infos = parse_model_name(model_path)
    layer_num = model_infos['layer_num']
    max_size = model_infos['max_size']
    
    # ê²Œì„ ì´ˆê¸°í™” (ë Œë”ë§ ëª¨ë“œ)
    game = RacingGame(track_file, car_json_path=car_json_path, headless=False)
    ori_checkpoints = copy.deepcopy(game.checkpoints)
    
    # ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ë° ëª¨ë¸ ë¡œë“œ
    agent = DQN(input_size=28, output_size=6, layer_num=layer_num, max_size=max_size)
    agent.load_model(model_path)
    
    # í°íŠ¸
    font = pygame.font.SysFont('arial,sans-serif', 18)
    big_font = pygame.font.SysFont('arial,sans-serif', 36)
    
    print("=" * 60)
    print("ğŸ® DQN MODEL EVALUATION")
    print(f"   Model: {model_path}")
    print(f"   Episodes: {num_episodes}")
    print(f"   Speed: {speed_multiplier}x")
    print("=" * 60)
    print("\nControls:")
    print("  ESC: Quit")
    print("  R: Reset current episode")
    print("  S: Toggle sensors")
    print("  Q: Toggle Q-values")
    print("  +/-: Adjust speed")
    print("=" * 60)
    
    episode = 0
    results = []
    running = True
    
    while running and episode < num_episodes:
        # ì—í”¼ì†Œë“œ ì‹œì‘
        game.reset()
        game.checkpoints = copy.deepcopy(ori_checkpoints)
        
        done = False
        current_action = 0
        frames_remaining = 0
        current_controls = agent.get_real_action(0)
        
        print(f"\nâ–¶ Episode {episode + 1}/{num_episodes} started")
        
        standard_cp = ori_checkpoints[0] if ori_checkpoints else game.end_pos
        dis_gap = math.dist([game.start_pos[0], game.start_pos[1]], 
                            [standard_cp[0], standard_cp[1]])
        
        while not done and running:
            # ì´ë²¤íŠ¸ ì²˜ë¦¬
            for event in pygame.event.get():
                if event.type == pygame.QUIT:
                    running = False
                elif event.type == pygame.KEYDOWN:
                    if event.key == pygame.K_ESCAPE:
                        running = False
                    elif event.key == pygame.K_r:
                        done = True  # ì—í”¼ì†Œë“œ ì¬ì‹œì‘
                        episode -= 1
                    elif event.key == pygame.K_s:
                        show_sensors = not show_sensors
                    elif event.key == pygame.K_q:
                        show_q_values = not show_q_values
                    elif event.key == pygame.K_PLUS or event.key == pygame.K_EQUALS:
                        speed_multiplier = min(speed_multiplier + 0.5, 5.0)
                        print(f"Speed: {speed_multiplier}x")
                    elif event.key == pygame.K_MINUS:
                        speed_multiplier = max(speed_multiplier - 0.5, 0.5)
                        print(f"Speed: {speed_multiplier}x")
            
            # í”„ë ˆì„ ìŠ¤í‚µì´ ëë‚˜ë©´ ìƒˆ ì•¡ì…˜ ì„ íƒ
            if frames_remaining <= 0:
                state = get_data(game, standard_cp, dis_gap)
                current_q_values, current_action = agent.predict(state)
                frames_remaining = agent.get_action_frames(current_action)
                current_controls = agent.get_real_action(current_action)
            
            # ê²Œì„ ìŠ¤í…
            _, step_done, info = game.step(current_controls)
            frames_remaining -= 1
            
            # ì²´í¬í¬ì¸íŠ¸ ì²˜ë¦¬
            if len(game.checkpoints_reached) > 0:
                cp_idx = game.checkpoints_reached.pop(0)
                reached_cp = game.checkpoints[cp_idx]
                game.checkpoints.pop(cp_idx)
                ori_cp_idx = ori_checkpoints.index(reached_cp)
                current_segment = ori_cp_idx + 1
                standard_cp = ori_checkpoints[ori_cp_idx + 1] if ori_cp_idx < len(ori_checkpoints) - 1 else game.end_pos
                dis_gap = math.dist([reached_cp[0], reached_cp[1]], 
                                    [standard_cp[0], standard_cp[1]])
            
            # ì¢…ë£Œ ì¡°ê±´
            if step_done:
                done = True
            
            # íƒ€ì„ì•„ì›ƒ
            if game.current_time / 1000 > 60:
                done = True
            
            # ë Œë”ë§
            game._draw()
            
            # ì¶”ê°€ ì‹œê°í™”
            # if show_sensors:
            #     draw_sensors(game.screen, game, (game.camera_x, game.camera_y))
            
            if show_q_values and current_q_values is not None:
                draw_q_values(game.screen, current_q_values, current_action, font)
            
            # ì—í”¼ì†Œë“œ ì •ë³´ í‘œì‹œ
            episode_text = big_font.render(f"Episode: {episode + 1}/{num_episodes}", True, (0, 0, 0))
            game.screen.blit(episode_text, (game.width - 250, 10))
            
            action_names = ['Forward', 'Fwd+Left', 'Fwd+Right', 'Drift L', 'Drift R', 'Brake']
            action_text = font.render(f"Action: {action_names[current_action]}", True, (0, 0, 0))
            game.screen.blit(action_text, (game.width - 250, 50))
            
            speed_text = font.render(f"Game Speed: {speed_multiplier}x", True, (0, 0, 0))
            game.screen.blit(speed_text, (game.width - 250, 70))
            
            pygame.display.flip()
            game.clock.tick(int(60 * speed_multiplier))
        
        # ì—í”¼ì†Œë“œ ê²°ê³¼ ê¸°ë¡
        if running:
            episode += 1
            episode_time = game.current_time / 1000
            
            result = {
                'episode': episode,
                'goal': game.goal_reached,
                'collision': game.collision,
                'time': episode_time
            }
            results.append(result)
            
            if game.goal_reached:
                print(f"  âœ“ GOAL! Time: {episode_time:.2f}s")
            elif game.collision:
                print(f"  âœ— CRASHED at {episode_time:.2f}s")
            else:
                print(f"  âœ— TIMEOUT at {episode_time:.2f}s")
    
    # ê²°ê³¼ ìš”ì•½
    print("ğŸ“Š EVALUATION RESULTS")
    print("=" * 60)
    
    success_count = sum(1 for r in results if r['goal'])
    success_times = [r['time'] for r in results if r['goal']]
    
    print(f"Success Rate: {success_count}/{len(results)} ({100*success_count/len(results):.1f}%)")
    
    if success_times:
        print(f"Average Goal Time: {np.mean(success_times):.3f}s")
        print(f"Best Time: {min(success_times):.3f}s")
        print(f"Worst Time: {max(success_times):.3f}s")
    
    print("=" * 60)
    
    pygame.quit()
    return results


if __name__ == "__main__":
    # ì„¤ì •
    MODEL_PATH = f"{os.path.join(current_dir, '..')}/example_models/dqn_best_lr_0_0003_L3_S512_E165054_T133_448.pth"  # ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
    TRACK_FILE = f"{os.path.join(current_dir, '..')}/env/track.json"
    CAR_JSON_PATH = f"{os.path.join(current_dir, '..')}/env/racing_car.json"
    
    # ëª¨ë¸ íŒŒì¼ëª…ì—ì„œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶”ì¶œ (í•„ìš”ì‹œ ìˆ˜ì •)
    LAYER_NUM = 3
    MAX_SIZE = 512
    
    # í‰ê°€ ì‹¤í–‰
    results = evaluate_dqn(
        model_path=MODEL_PATH,
        track_file=TRACK_FILE,
        car_json_path=CAR_JSON_PATH,
        layer_num=LAYER_NUM,
        max_size=MAX_SIZE,
        num_episodes=10,
        show_sensors=False,
        show_q_values=True,
        speed_multiplier=1.0
    )